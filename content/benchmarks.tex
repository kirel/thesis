%!TEX root = /Users/daniel/Documents/thesis/thesis.tex
\chapter{Benchmarks} % (fold)
\label{cha:benchmarks}

In diesem Kapitel stelle ich Benchmarks vor auf Basis der durch die Nutzer zur Verfügung gestellten Daten vor (siehe \ref{sec:crowdsourcing}). Ich habe Benchmarks mit einem kleinen Datensatz und einem großen Datensatz durchgeführt. Der kleine Datensatz wurde verwendet, um die Parameter zu optimieren. Durch die relativ geringe Anzahl der Tests konnte so in schnellen Iterationen eine große Menge an Benchmarks durchgeführt werden. Der große Benchmark dient dazu einen Blick auf die Performance des im Einsatz befindlichen Systems unter realen Bedingungen zu liefern und vor allem um festzustellen ob die in \ref{sec:klassifizierung} geforderte \emph{Skalierbarkeit} und ein ausreichend gutes \emph{Laufzeitverhalten} realisiert sind.

\section{Kleiner Datensatz}
\label{sec:kleiner_datensatz}

In diesem Abschnitt werden mithilfe eines Teils der verfügbaren Trainingsdaten die DTW-Varianten auf ihre Güte überprüft und die Parameter optimiert. Dabei wird auf die folgende Weise verfahren. Zuerst werden mit fest gewählten Parametern $C$, $\delta$ und $n$ \ac{DTW} und \ac{GDTW} gegeneinander getestet. Dann werden nach und nach die unterschiedlichen Parameter einzeln unter Fixierung der restlichen Parameter variiert und so ein optimaler Wert erhalten.

Der kleine Datensatz besteht aus 100 zufällig aus der Datenbank ausgewählten Symbolen. Aus den vorhandenen Trainingsmustern wurden pro Symbolklasse 75 zufällig ausgewählt und davon wurden 50 für das Training des Servers und 25 als Testmuster verwendet. Dies ergibt 2500 Tests.

Folgende Symbole wurden verwendet:

\begin{quote}
$\$$,
$\{$,
$\copyright$,
$\}$,
$\S$,
$\&$,
$\#$,
$\%$,
$\checkmark$,
\aa,
\AA,
\ae,
\DH,
\DJ,
\EUR,
$\cup$,
$\oplus$,
$\times$,
$\ast$,
$\otimes$,
$\pm$,
$\cap$,
$\vee$,
$\cdot$,
$\odot$,
$\wedge$,
$\circ$,
$\bigotimes$,
$\prod$,
$\sum$,
$\bigodot$,
$\int$,
$\oint$,
$\approx$,
$\equiv$,
$\perp$,
$\cong$,
$\propto$,
$\vdash$,
$\sim$,
$\simeq$,
$\therefore$,
$\because$,
$\subseteq$,
$\geq$,
$\leq$,
$\ll$,
$\neq$,
$\lesssim$,
$\gtrsim$,
$\triangleq$,
$\Rightarrow$,
$\rightarrow$,
$\Leftrightarrow$,
$\mapsto$,
$\alpha$,
$\theta$,
$\tau$,
$\beta$,
$\vartheta$,
$\pi$,
$\gamma$,
$\phi$,
$\delta$,
$\rho$,
$\varphi$,
$\epsilon$,
$\lambda$,
$\chi$,
$\varepsilon$,
$\mu$,
$\sigma$,
$\psi$,
$\zeta$,
$\nu$,
$\omega$,
$\eta$,
$\xi$,
$\Gamma$,
$\Lambda$,
$\Sigma$,
$\Psi$,
$\Delta$,
$\Xi$,
$\Omega$,
$\Theta$,
$\Pi$,
$\Phi$,
$\bot$,
$\forall$,
$\ell$,
$\hbar$,
$\in$,
$\not\in$,
$\partial$,
$\exists$,
$[$,
$/$,
$\aleph$,
$\infty$
\end{quote}

Davon sind manche, wie $\odot$ (\verb!\odot!) und $\bigodot$ (\verb!\bigodot!) oder $\sum$(\verb!\sum!) und $\Sigma$~(\verb!\Sigma!) eigentlich dieselben Symbole. Es wurden aber keine Maßnahmen ergriffen, um solche Zweideutigkeiten aufzuheben, da durch die Interaktivität der Anwendung ohnehin in erste Linie eine hohe Top 5-Erkennungsrate wichtig ist.

\subsection{DTW-Variante}
\label{sub:gierig_oder_nicht}

Der erste Benchmark testet DTW in seiner klassischen Form gegen die Greedy-Approximation GDTW. Dabei wurde erst einmal $C=50$, $n=25$ (optimal nach \citet{Golubitsky:2009p1842}) und das Abstandsmaß $\delta$ als die euklidische Metrik festgelegt. Abbildung \ref{chart:dtw-vs-gdtw} illustriert die Ergebnisse. Es zeigt sich, dass GDTW kaum schlechter abschneidet, als DTW und dabei, wie aus Abbildung \ref{chart:dtw-vs-gdtw-ms} ersichtlich ist, wesentlich schneller ist. Dies bestätigt die Ergebnisse von \citet{MacLean:2010p9970}, die ebenfalls eine Greedy-Variante von DTW verwenden.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=\textwidth]{charts/dtw-vs-gdtw.pdf}
  \end{center}
  \caption{Greedy DTW gegen klassisches DTW}
  \label{chart:dtw-vs-gdtw}
\end{figure}

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=.75\textwidth]{charts/dtw-vs-gdtw-ms.pdf}
  \end{center}
  \caption{Greedy DTW gegen klassisches DTW - Laufzeit}
  \label{chart:dtw-vs-gdtw-ms}
\end{figure}

Auf Basis dieser Daten fällt es leicht die Auswahl des Verfahrens für Detexify auf GDTW festzulegen und im Folgenden die Betrachtungen auf dieses zu beschränken.

% chapter benchmarks (end)

\subsection{Inneres Abstandsmaß} % (fold)
\label{sub:inneres_abstandsmaß}

Abbildung \ref{chart:dtw-vs-gdtw} zeigt neben den Erkennungsraten von DTW und GDTW mit euklidischer Metrik als Abstandsmaß auch noch die Erkennungsraten von GDTW mit der Manhattan-Metrik als Abstandsmaß, die als

\[ d(x,y) = \sum_i a_i - b_i \]

definiert ist (mit $C=50$, $n=25$). Dieses Abstandsmaß ist nicht nur günstiger in der Berechnung, sondern liefert auch noch eine leichte Verbesserung der Top 5-Erkennungsrate um 0,6\%. Die folgenden Benchmarks wurden daher alle mit der Manhattan-Metrik $d$ als innerem Abstandsmaß $\delta$ durchgeführt.

\subsection{Anzahl Trainingsmuster} % (fold)
\label{sub:anzahl_trainingsmuster}

Die Anzahl der verwendeten Trainingsmuster $C$ hat natürlich einen Einfluss auf die Erkennungsraten.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=.75\textwidth]{charts/samples.pdf}
  \end{center}
  \caption{Einfluss der Anzahl der Trainingsmuster $C$}
  \label{chart:samples}
\end{figure}

Abbildung \ref{chart:samples} zeigt, dass, anders als \citet{Golubitsky:2009p1842} für ihre Tests beschreiben, die Erkennungsraten (insb. Top 1) für $C > 25$ noch deutlich steigen (weiterhin $n=25$). Dies liegt vermutlich an einer höheren Variation in meinen Trainingsdaten, so dass sich eine größere Datenbasis auszahlt. Die Wahl von $C=50$ wurde jedoch beibehalten und nicht noch weiter erhöht, denn $C$ wirkt sich linear auf die Laufzeit des Erkennungsvorgangs aus.
% subsection anzahl_klassen (end)

\subsection{Anzahl Punkte pro Strich} % (fold)
\label{sub:anzahl_punkte_pro_strich}

Die Anzahl der Punkte pro Strich $n$ hat ebenso sowohl einen Einfluss auf die Erkennungsrate als auch auf die Laufzeit. Abbildung \ref{chart:points} zeigt dass mit $C=50$ ab $n=10$ gerade die Top 1-Erkennungsrate mit sinkendem $n$ stark abnimmt. Die Top 5-Erkennungsrate bleibt jedoch recht stabil. Für die weiteren Tests wurde $n=10$ als optimal festgelegt, da dies nur geringe Einbußen in der Erkennung bei einer gut Laufzeit liefert.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=.75\textwidth]{charts/points.pdf}
  \end{center}
  \caption{Einfluss der Anzahl der Punkte pro Strich $n$}
  \label{chart:points}
\end{figure}

% subsection anzahl_punkte_pro_strich (end)

\subsection{Dominante Punkte} % (fold)
\label{sub:dominante_punkte}

Alle bisherigen Tests wurden ohne die Filterung von Punkten mit geringer Krümmung vorgenommen. In diesem Benchmark wurde diese Filterung mit unterschiedlichen Grenzwinkeln $\alpha$ nach der äquidistanten Verteilung der Punkte durchgeführt. Die Parameter $C=50$, $n=10$ und $\delta=d$ bleiben dabei fix. Abbildung \ref{chart:degree} zeigt, dass beim optimalen Grenzwinkel $\alpha=15\degree$ die Erkennungsraten von dieser Maßnahme richtig profitieren. Die Top 1-Erkennungsrate steigt um 1,48\% und die Top 5-Erkennungsrate sogar um 1.6\%.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=.75\textwidth]{charts/degree.pdf}
  \end{center}
  \caption{Einfluss des Winkels $\alpha$}
  \label{chart:degree}
\end{figure}

% subsection dominante_punkte (end)

\section{Großer Datensatz}
\label{sec:grosser_datensatz}

\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=\textwidth]{charts/large.pdf}
  \end{center}
  \caption{Ergebnisse mit dem großen Datensatz}
  \label{chart:large}
\end{figure}

Der Bechmark mit dem großen Datensatz wurde mit den im vorherigen Abschnitt experimentell gefundenen optimalen Parametern $C=50$, $n=10$, $\delta=d$ und $\alpha=15\degree$ durchgeführt. Dafür wurden die Symbolen aus der Datenbank ausgewählt, die mindestes 15 Trainingsmuster hatten. Von diesen wurden bis zu 100 Trainingsmuster ausgewählt und mit zwei Dritteln davon wurde jeweils der Server trainiert und der Rest als Testmuster verwendet.

Der Benchmark umfasst damit 627 Symbole. 27460 Trainingsmuster stehen 13411 Testmustern gegenüber.

Abbildung \ref{chart:large} zeigt die Ergebnisse. Mit einer Top 5-Erkennungsrate von 84,52\% ist das System zwar weit von Zahlen entfernt, die in der Literatur auftauchen, aber die Erklärung ist recht einfach, wenn man sich die folgende Statistik aus dem Testprotokoll ansieht, die die Symbole mit den besten und schlechtesten Testergebnissen auflistet:

\begin{verbatim}
  Top 10 Symbols:
  \cong (latex2e, OT1) - 93,94% top 1
  \not\equiv (latex2e, OT1) - 93,94% top 1
  \& (latex2e, OT1) - 93,94% top 1
  \supset (latex2e, OT1) - 93,94% top 1
  \asymp (latex2e, OT1) - 90,91% top 1
  \approxeq (amssymb, OT1) - 90,91% top 1
  \neq (amssymb, OT1) - 90,91% top 1
  \gtrsim (amssymb, OT1) - 90,91% top 1
  \rightharpoonup (latex2e, OT1) - 90,91% top 1
  \circledR (amssymb, OT1) - 90,91% top 1
\end{verbatim}
  
\begin{verbatim}
  Flop 10 Symbols:
  \ddag (latex2e, OT1) - 0,0% top 1
  \dotso (amsmath, OT1) - 0,0% top 1
  \Updelta (upgreek, OT1) - 0,0% top 1
  \ldotp (latex2e, OT1) - 0,0% top 1
  \dotsi (amsmath, OT1) - 0,0% top 1
  \Rbag (stmaryrd, OT1) - 0,0% top 1
  \dots (latex2e, OT1) - 0,0% top 1
  \Uppi (upgreek, OT1) - 0,0% top 1
  \Gemini (marvosym, OT1) - 0,0% top 1
  \therefore (amssymb, OT1) - 0,0% top 1
\end{verbatim}

Es ist so, dass die Symbole aus der Top 10-Liste ($\cong$, $\not\equiv$, \&, $\supset$, etc.) erstens relativ eindeutige Symbole sind und andererseits über eine große Trainingsdatenmenge verfügen. Die Symbole aus der Flop 10-Liste hingegen haben allesamt eine sehr kleine Trainingsmenge (<20) und sind häufig sehr ähnlich zu mindestens einem anderen Symbol, das eine wesentlich bessere Trainingsbasis hat (teilweise >1000), wie z.B. \verb!\Updelta! ($\Updelta$) und \verb!\Delta! ($\Delta$) oder \verb!\Rbag! ($\Rbag$) und \verb!\int! ($\int$). Zwar werden maximal $C=50$ Trainingsmuster je Klasse verwendet, aber es ist eine bekannte (und offensichtliche) Schwäche der Nächste-Nachbarn-Klassifikation, dass Klassen mit einer höheren Anzahl an Trainingsmustern bevorzugt ausgewählt werden, da die Wahrscheinlichkeit, dass der nächste Nachbar aus einer dieser Klassen kommt, alleine schon aufgrund der Häufigkeit höher sein muss.

\section{Ergebnis}

\TODO Ich erkläre die Daten hiermit für Okay...